# -*- coding: utf-8 -*-
"""PA_Sampling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DmCEvMGnMbe_yIZtZtH6KdN2V6jwfgGE
"""

#rebalancing
!pip install imbalanced-learn

import pandas as pd
import numpy as np
import csv
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.calibration import CalibratedClassifierCV
from imblearn.over_sampling import RandomOverSampler
from collections import Counter

data = np.loadtxt('heart.dat', unpack = True)
a = data.transpose()
header_list = ["1","2","3","4","5","6","7","8","9","10","11","12","13","target"]
np.savetxt('heart.csv', a, delimiter=',')

dataset = pd.read_csv("heart.csv", names=header_list)
dataset.target.replace({1:0, 2:1}, inplace = True)

dataset

frame = pd.DataFrame(dataset.target, columns=['target'])
print(frame['target'].value_counts())

X = dataset.iloc[:,0:13]
y = dataset.iloc[:,13]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=dataset.target)

fp = np.full((y_test.shape[0],1), 1)
fn = np.full((y_test.shape[0],1), 5)
tp = np.zeros((y_test.shape[0],1))
tn = np.zeros((y_test.shape[0],1))
cost_matrix = np.hstack((fp, fn, tp, tn))

cost_m = [[0 , 5], [1, 0]]
print("\nCost matrix: ", cost_m)

#RANDOM FOREST

RF_clf = RandomForestClassifier(n_estimators=100, random_state=0)

print("Random forest without sampling")
print(Counter(y_train))

model = RF_clf.fit(X_train, y_train)
y_pred = RF_clf.predict(X_test)
t_names = ['Absence', 'Presence']
print(classification_report(y_test, y_pred, target_names=t_names))
conf_m = confusion_matrix(y_test, y_pred).T 
print(conf_m)
loss = np.sum(conf_m * cost_m)
print("%d\n" %loss)

print("Random Forest with oversampling")
sampler = RandomOverSampler(sampling_strategy={0: 105, 1: 420}, random_state=1)
X_rs, y_rs = sampler.fit_resample(X_train, y_train)
print(Counter(y_rs))

model = RF_clf.fit(X_rs, y_rs)
y_pred = RF_clf.predict(X_test)
t_names = ['Absence', 'Presence']
print(classification_report(y_test, y_pred, target_names=t_names))
conf_m = confusion_matrix(y_test, y_pred).T
print(conf_m)
loss = np.sum(conf_m * cost_m)
print("%d\n" %loss)

#SVM

SVM_clf = SVC(kernel='linear', C=1)

print("SVM without sampling")
print(Counter(y_train))

model = SVM_clf.fit(X_train, y_train)
y_pred = SVM_clf.predict(X_test)
t_names = ['Absence', 'Presence']
print(classification_report(y_test, y_pred, target_names=t_names))
conf_m = confusion_matrix(y_test, y_pred).T 
print(conf_m)
loss = np.sum(conf_m * cost_m)
print("%d\n" %loss)

print("SVM with oversampling")
sampler = RandomOverSampler(sampling_strategy={0: 105, 1: 420}, random_state=1)
X_rs, y_rs = sampler.fit_resample(X_train, y_train)
print(Counter(y_rs))

model = SVM_clf.fit(X_rs, y_rs)
y_pred = SVM_clf.predict(X_test)
t_names = ['Absence', 'Presence']
print(classification_report(y_test, y_pred, target_names=t_names))
conf_m = confusion_matrix(y_test, y_pred).T
print(conf_m)
loss = np.sum(conf_m * cost_m)
print("%d\n" %loss)

#Naive Bayes

NB_clf = GaussianNB()

print("Naive Bayes without sampling")
print(Counter(y_train))

model = NB_clf.fit(X_train, y_train)
y_pred = NB_clf.predict(X_test)
t_names = ['Absence', 'Presence']
print(classification_report(y_test, y_pred, target_names=t_names))
conf_m = confusion_matrix(y_test, y_pred).T 
print(conf_m)
loss = np.sum(conf_m * cost_m)
print("%d\n" %loss)

print("Naive Bayes with oversampling")
sampler = RandomOverSampler(sampling_strategy={0: 105, 1: 420}, random_state=1)
X_rs, y_rs = sampler.fit_resample(X_train, y_train)
print(Counter(y_rs))

model = NB_clf.fit(X_rs, y_rs)
y_pred = NB_clf.predict(X_test)
t_names = ['Absence', 'Presence']
print(classification_report(y_test, y_pred, target_names=t_names))
conf_m = confusion_matrix(y_test, y_pred).T 
print(conf_m)
loss = np.sum(conf_m * cost_m)
print("%d\n" %loss)
